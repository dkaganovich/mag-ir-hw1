{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим набор вспомогательных классов и функций:\n",
    "\n",
    "*Remark: функции eval_output, f1_score и precision используют модифицированный код из eval.py. В частности в исходном скрипте при оценке игнорировался самый релевантный запросу документ.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "\n",
    "# primary language\n",
    "_lang = \"english\"\n",
    "\n",
    "# raw data sources\n",
    "_doc_raw_file = \"data/cran.all.1400\"\n",
    "_query_raw_file = \"data/cran.qry\"\n",
    "\n",
    "# this applies only to _persistent_mode = True\n",
    "_doc_db_file = \"data/doc_db.dat\"\n",
    "_query_db_file = \"data/query_db.dat\"\n",
    "_doc_index_file = \"data/doc_index.dat\"\n",
    "\n",
    "_groundtruth_file = \"data/qrel_clean\"\n",
    "# search results for evaluation\n",
    "_answer_file = \"data/train.qrel_clean\"\n",
    "\n",
    "# switch to turn on/off flushing data to disk\n",
    "_persistent_mode = False\n",
    "\n",
    "\n",
    "class TextAnalyzer(object):\n",
    "    \"\"\"docstring for TextAnalyzer\"\"\"\n",
    "    def __init__(self, lang, stemmer = None, lemmatizer = None):\n",
    "        super(TextAnalyzer, self).__init__()\n",
    "        self.lang = lang\n",
    "        self.stemmer = stemmer\n",
    "        self.lemmatizer = lemmatizer\n",
    "        self.stopwords = set(stopwords.words(lang))\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        result = []\n",
    "        for token in word_tokenize(text):\n",
    "            token = token.lower().translate(None, string.punctuation)\n",
    "            if not token or token in self.stopwords:\n",
    "                continue\n",
    "            if self.lemmatizer is not None:\n",
    "                token = self.lemmatizer.lemmatize(token)\n",
    "            if self.stemmer is not None:\n",
    "                token = self.stemmer.stem(token)\n",
    "            result.append(token)\n",
    "        return result\n",
    "\n",
    "\n",
    "class DataParser(object):\n",
    "    \"\"\"docstring for DataParser\"\"\"\n",
    "    def __init__(self, pattern):\n",
    "        super(DataParser, self).__init__()\n",
    "        self.pattern = re.compile(pattern, re.S)\n",
    "        \n",
    "    def stream_data(self, path):\n",
    "        with open(path) as fd:\n",
    "            for result in self.pattern.findall(fd.read()):\n",
    "                yield result\n",
    "\n",
    "\n",
    "class Document(object):\n",
    "    \"\"\"docstring for Document\"\"\"\n",
    "    def __init__(self, id_, title, abstract, meta = None):\n",
    "        super(Document, self).__init__()\n",
    "        self.id_ = id_\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.meta = meta if meta is not None else dict()\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"id_={}\\ntitle={}\\nabstract={}\\nmeta={}\"\\\n",
    "                .format(str(self.id_), str(self.title), str(self.abstract), str(self.meta))\n",
    "\n",
    "\n",
    "class Query(object):\n",
    "    \"\"\"docstring for Query\"\"\"\n",
    "    def __init__(self, id_, body):\n",
    "        super(Query, self).__init__()\n",
    "        self.id_ = id_\n",
    "        self.body = body\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"id_={}\\nbody={}\"\\\n",
    "                .format(str(self.id_), str(self.body))\n",
    "\n",
    "\n",
    "class Database(object):\n",
    "    \"\"\"docstring for Database\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Database, self).__init__()\n",
    "        self.db = dict()\n",
    "        \n",
    "    def add(self, item_id, item):\n",
    "        self.db[item_id] = item\n",
    "\n",
    "    def find(self, item_id):\n",
    "        return self.db.get(item_id, None)\n",
    "\n",
    "    def stats_output(self):\n",
    "        print \"db size: {} item(s)\".format(len(self.db))\n",
    "\n",
    "\n",
    "class Posting(object):\n",
    "    \"\"\"docstring for Posting\"\"\"\n",
    "    def __init__(self, id_, tf):\n",
    "        super(Posting, self).__init__()\n",
    "        self.id_ = id_\n",
    "        self.tf = tf\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"id_={}\\ntf={}\"\\\n",
    "                .format(str(self.id_), str(self.tf))\n",
    "\n",
    "\n",
    "class InvertedIndex(object):\n",
    "    \"\"\"docstring for InvertedIndex\"\"\"\n",
    "    def __init__(self, text_analyzer):\n",
    "        super(InvertedIndex, self).__init__()\n",
    "        self.text_analyzer = text_analyzer\n",
    "        self.index = dict()\n",
    "        \n",
    "    def add(self, item_id, item, index_field):\n",
    "        content = getattr(item, index_field)\n",
    "        tokens = self.text_analyzer.tokenize(content)\n",
    "        tokens.sort()\n",
    "        token = None\n",
    "        tf = 0\n",
    "        for i in xrange(len(tokens)):\n",
    "            if token != tokens[i]:\n",
    "                if token is not None:\n",
    "                    if token not in self.index:\n",
    "                        self.index[token] = []\n",
    "                    self.index[token].append(Posting(item_id, tf))\n",
    "                token = tokens[i]\n",
    "                tf = 0\n",
    "            tf += 1\n",
    "            if i + 1 == len(tokens):\n",
    "                if token not in self.index:\n",
    "                    self.index[token] = []\n",
    "                self.index[token].append(Posting(item_id, tf))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def find(self, token):\n",
    "        return self.index.get(token, [])\n",
    "    \n",
    "    def stats_output(self):\n",
    "        voc_len = len(self.index)\n",
    "        aver_plen, max_plen, max_token = 0, 0, None\n",
    "        for token, postings in self.index.iteritems():\n",
    "            plen = len(postings)\n",
    "            aver_plen += plen\n",
    "            if max_plen < plen:\n",
    "                max_plen = plen\n",
    "                max_token = token\n",
    "        aver_plen /= float(voc_len)\n",
    "        print \"vocabulary length: {}\\npostings length (average): {}\\npostings length (max): {} - \\'{}\\'\"\\\n",
    "                .format(voc_len, aver_plen, max_plen, max_token)\n",
    "            \n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        del state[\"text_analyzer\"]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "\n",
    "\n",
    "class BM25Ranker(object):\n",
    "    \"\"\"docstring for BM25Ranker\"\"\"\n",
    "    def __init__(self, k1, b, k2 = None):\n",
    "        super(BM25Ranker, self).__init__()\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.k2 = k2\n",
    "        \n",
    "    def score(self, tfd, N, Nt, L, Ld, tfq = None):\n",
    "        tfidf = self.idf(N, Nt) * self.tfd(tfd, L, Ld)\n",
    "        if self.k2 is not None and tfq is not None:\n",
    "            return tfidf * self.tfq(tfq)\n",
    "        else:\n",
    "            return tfidf\n",
    "        \n",
    "    def idf(self, N, Nt):\n",
    "        return math.log(1 + ((N - Nt + 0.5) / (Nt + 0.5)))\n",
    "\n",
    "    def tfd(self, tfd, L, Ld):\n",
    "        return (tfd * (self.k1 + 1)) / (self.k1 * ((1 - self.b) + self.b * Ld / float(L)) + tfd)\n",
    "\n",
    "    def tfq(self, tfq):\n",
    "        return ((self.k2 + 1) * tfq) / float(self.k2 + tfq)\n",
    "\n",
    "\n",
    "class BM25AltIDFRanker(BM25Ranker):\n",
    "    \"\"\"docstring for BM25AltIDFRanker\"\"\"\n",
    "    def __init__(self, k1, b, k2 = None):\n",
    "        super(BM25AltIDFRanker, self).__init__(k1, b, k2)\n",
    "\n",
    "    def idf(self, N, Nt):\n",
    "        return math.log(N / float(Nt))\n",
    "\n",
    "\n",
    "class SearchEngine(object):\n",
    "    \"\"\"docstring for SearchEngine\"\"\"\n",
    "    def __init__(self, text_analyzer, bm25_ranker, doc_index, doc_db):\n",
    "        super(SearchEngine, self).__init__()\n",
    "        self.text_analyzer = text_analyzer\n",
    "        self.bm25_ranker = bm25_ranker\n",
    "        self.doc_index = doc_index\n",
    "        self.doc_db = doc_db\n",
    "        # \n",
    "        self.N = len(self.doc_db.db)\n",
    "        self.L = sum(doc.meta[\"tokenized_len\"] for doc in self.doc_db.db.itervalues()) / float(self.N)\n",
    "        \n",
    "    def run_or_query(self, query, limit, normalize = False, threshold = None):\n",
    "        query_index = InvertedIndex(self.text_analyzer)\n",
    "        query_index.add(query.id_, query, \"body\")\n",
    "        if len(query_index.index) == 0:\n",
    "            return []\n",
    "        if normalize:\n",
    "            idf = dict()\n",
    "        rsv = dict()\n",
    "        for token in self.text_analyzer.tokenize(query.body):\n",
    "            tfq = query_index.find(token)[0].tf\n",
    "            postings = self.doc_index.find(token)\n",
    "            for posting in postings:\n",
    "                tfd = posting.tf\n",
    "                Nt = len(postings)\n",
    "                Ld = self.doc_db.find(posting.id_).meta[\"tokenized_len\"]\n",
    "                if normalize:\n",
    "                    idf[posting.id_] = idf.get(posting.id_, 0) + self.bm25_ranker.idf(self.N, Nt)\n",
    "                rsv[posting.id_] = rsv.get(posting.id_, 0) + self.bm25_ranker.score(tfd, self.N, Nt, self.L, Ld, tfq)\n",
    "        \n",
    "        if normalize:\n",
    "            for doc_id, score in rsv.iteritems():\n",
    "                rsv[doc_id] /= float(idf[doc_id])\n",
    "        \n",
    "        result = sorted(rsv.iteritems(), key = lambda e: e[1], reverse = True)[:limit]\n",
    "        if threshold is not None:\n",
    "            return [(doc_id, score) for doc_id, score in result if score >= min(result[0][1], threshold)]\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "def objdump(obj, path):\n",
    "    with open(path, \"wb\") as fd:\n",
    "        pickle.dump(obj, fd, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def objload(path):\n",
    "    with open(path, \"rb\") as fd:\n",
    "        return pickle.load(fd)\n",
    "\n",
    "\n",
    "def parse_documents():\n",
    "    doc_db = Database()\n",
    "    doc_parser = DataParser(\"\\.I\\s(\\d+)\\n\\.T\\n(.*?)\\.A.*?\\.W\\n(.*?)(?=(\\.I|$))\")\n",
    "    for data in doc_parser.stream_data(_doc_raw_file):\n",
    "        id_, title, abstract = int(data[0]), data[1], data[2]\n",
    "        doc_db.add(id_, Document(id_, title, abstract))\n",
    "    if _persistent_mode:\n",
    "        objdump(doc_db, _doc_db_file)\n",
    "    return doc_db\n",
    "\n",
    "\n",
    "def parse_queries():\n",
    "    query_db = Database()\n",
    "    query_parser = DataParser(\"\\.W\\n(.*?)(?=(\\.I|$))\")\n",
    "    id_ = 0\n",
    "    for data in query_parser.stream_data(_query_raw_file):\n",
    "        id_ += 1\n",
    "        body = data[0]\n",
    "        query_db.add(id_, Query(id_, body))\n",
    "    if _persistent_mode:\n",
    "        objdump(query_db, _query_db_file)\n",
    "    return query_db\n",
    "\n",
    "\n",
    "def index(text_analyzer, index_field, doc_db):\n",
    "    doc_index = InvertedIndex(text_analyzer)\n",
    "    for doc in doc_db.db.itervalues():\n",
    "        doc.meta[\"tokenized_len\"] = doc_index.add(doc.id_, doc, index_field)\n",
    "    if _persistent_mode:\n",
    "        objdump(doc_index, _doc_index_file)\n",
    "        objdump(doc_db, _doc_db_file)\n",
    "    return doc_index\n",
    "\n",
    "\n",
    "def search(text_analyzer, ranker, doc_index, doc_db, query_db, limit, normalize = False, threshold = None):    \n",
    "    engine = SearchEngine(text_analyzer, ranker, doc_index, doc_db)\n",
    "    with open(_answer_file, \"w\") as fd:\n",
    "        for query in query_db.db.itervalues():\n",
    "            docset = engine.run_or_query(query, limit, normalize, threshold)\n",
    "            for doc in docset:\n",
    "                fd.write(str(query.id_) + \" \" + str(doc[0]) + \"\\n\")\n",
    "\n",
    "\n",
    "def eval_output():\n",
    "    q2reld = {} \n",
    "    for line in open(_groundtruth_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2reld:\n",
    "            q2reld[qid] = set()\n",
    "        q2reld[qid].add(did)\n",
    "    # \n",
    "    q2retrd = {}\n",
    "    for line in open(_answer_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2retrd:\n",
    "            q2retrd[qid] = []\n",
    "        q2retrd[qid].append(did)\n",
    "    # \n",
    "    N = len(q2retrd.keys())\n",
    "    precision = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2retrd[q]) for q in q2retrd.keys()]) / N\n",
    "    recall = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2reld[q]) for q in q2retrd.keys()]) / N\n",
    "    print(\"mean precision: {}\\nmean recall: {}\\nmean F-measure: {}\"\\\n",
    "          .format(precision, recall, 2*precision*recall/(precision+recall)))\n",
    "    # MAP@10\n",
    "    MAP = 0.0\n",
    "    for q in q2retrd.keys():\n",
    "        n_results = min(10, len(q2retrd[q]))\n",
    "        avep = np.zeros(n_results)\n",
    "        for i in range(n_results):\n",
    "            avep[i:] += q2retrd[q][i] in q2reld[q]\n",
    "            avep[i] *= (q2retrd[q][i] in q2reld[q]) / (i+1.0)\n",
    "        MAP += sum(avep) / min(n_results, len(q2reld[q]))\n",
    "    print(\"MAP@10: {}\".format(MAP/N))\n",
    "\n",
    "\n",
    "def f1_score():\n",
    "    q2reld = {} \n",
    "    for line in open(_groundtruth_file):\n",
    "        qid, did = [int(x) for x in line.split()]        \n",
    "        if qid not in q2reld:\n",
    "            q2reld[qid] = set()\n",
    "        q2reld[qid].add(did)\n",
    "\n",
    "    # \n",
    "    q2retrd = {}\n",
    "    for line in open(_answer_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2retrd:\n",
    "            q2retrd[qid] = []\n",
    "        q2retrd[qid].append(did)\n",
    "    # \n",
    "    N = len(q2retrd.keys())\n",
    "    precision = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2retrd[q]) for q in q2retrd.keys()]) / N\n",
    "    recall = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2reld[q]) for q in q2retrd.keys()]) / N\n",
    "    return 2*precision*recall/(precision+recall)\n",
    "\n",
    "def precision():\n",
    "    q2reld = {} \n",
    "    for line in open(_groundtruth_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2reld:\n",
    "            q2reld[qid] = set()\n",
    "        q2reld[qid].add(did)\n",
    "    # \n",
    "    q2retrd = {}\n",
    "    for line in open(_answer_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2retrd:\n",
    "            q2retrd[qid] = []\n",
    "        q2retrd[qid].append(did)\n",
    "    # \n",
    "    N = len(q2retrd.keys())\n",
    "    precision = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2retrd[q]) for q in q2retrd.keys()]) / N\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распарсим данные о статьях и запросы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------doc_db------\n",
      "db size: 1400 item(s)\n",
      "\n",
      "------query_db------\n",
      "db size: 225 item(s)\n"
     ]
    }
   ],
   "source": [
    "# _persistent_mode = True\n",
    "\n",
    "print \"------doc_db------\"\n",
    "_doc_db = parse_documents()\n",
    "_doc_db.stats_output()\n",
    "\n",
    "print \"\\n------query_db------\"\n",
    "_query_db = parse_queries()\n",
    "_query_db.stats_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим при каком способе нормализации и выборе индексируемого поля мы получим наилучшее качество поиска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------index_field = 'title'------\n",
      "\n",
      "text_analyzer idx = 0:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 1914\n",
      "postings length (average): 5.65987460815\n",
      "postings length (max): 319 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.224888888889\n",
      "mean recall: 0.330929412138\n",
      "mean F-measure: 0.267793801171\n",
      "MAP@10: 0.255775316341\n",
      "\n",
      "text_analyzer idx = 1:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 1479\n",
      "postings length (average): 7.30696416498\n",
      "postings length (max): 359 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.246666666667\n",
      "mean recall: 0.361286927292\n",
      "mean F-measure: 0.293171857033\n",
      "MAP@10: 0.28750920467\n",
      "\n",
      "text_analyzer idx = 2:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 1718\n",
      "postings length (average): 6.29511059371\n",
      "postings length (max): 359 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.238666666667\n",
      "mean recall: 0.35039711472\n",
      "mean F-measure: 0.283935675634\n",
      "MAP@10: 0.276800512304\n",
      "\n",
      "text_analyzer idx = 3:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 1477\n",
      "postings length (average): 7.31685849695\n",
      "postings length (max): 359 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.246222222222\n",
      "mean recall: 0.360539131877\n",
      "mean F-measure: 0.292611734907\n",
      "MAP@10: 0.288182203746\n",
      "\n",
      "------index_field = 'abstract'------\n",
      "\n",
      "text_analyzer idx = 0:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 8974\n",
      "postings length (average): 10.2041453087\n",
      "postings length (max): 686 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.286666666667\n",
      "mean recall: 0.412932806961\n",
      "mean F-measure: 0.33840526127\n",
      "MAP@10: 0.33706111811\n",
      "\n",
      "text_analyzer idx = 1:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 6240\n",
      "postings length (average): 13.7325320513\n",
      "postings length (max): 714 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.294666666667\n",
      "mean recall: 0.427313910957\n",
      "mean F-measure: 0.348804856154\n",
      "MAP@10: 0.363613863694\n",
      "\n",
      "text_analyzer idx = 2:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 8149\n",
      "postings length (average): 10.841452939\n",
      "postings length (max): 712 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.298222222222\n",
      "mean recall: 0.429201954553\n",
      "mean F-measure: 0.351920006938\n",
      "MAP@10: 0.357028554632\n",
      "\n",
      "text_analyzer idx = 3:\n",
      "---INDEX STATS---\n",
      "vocabulary length: 6232\n",
      "postings length (average): 13.743902439\n",
      "postings length (max): 714 - 'flow'\n",
      "---SEARCH STATS---\n",
      "mean precision: 0.296\n",
      "mean recall: 0.430382694025\n",
      "mean F-measure: 0.350760772467\n",
      "MAP@10: 0.363368566809\n"
     ]
    }
   ],
   "source": [
    "def task45(index_field):\n",
    "    print \"\\n------index_field = \\'{}\\'------\".format(index_field)\n",
    "    text_analyzers = [TextAnalyzer(_lang), \\\n",
    "                  TextAnalyzer(_lang, stemmer = SnowballStemmer(_lang)), \\\n",
    "                  TextAnalyzer(_lang, lemmatizer = WordNetLemmatizer()), \\\n",
    "                  TextAnalyzer(_lang, stemmer = SnowballStemmer(_lang), lemmatizer = WordNetLemmatizer())]\n",
    "    ranker = BM25Ranker(1.2, 0.75)\n",
    "    for i in xrange(len(text_analyzers)):\n",
    "        print \"\\ntext_analyzer idx = {}:\".format(i)\n",
    "        doc_index = index(text_analyzers[i], index_field, _doc_db)\n",
    "        print \"---INDEX STATS---\"\n",
    "        doc_index.stats_output()\n",
    "        search(text_analyzers[i], ranker, doc_index, _doc_db, _query_db, 10)\n",
    "        print \"---SEARCH STATS---\"\n",
    "        eval_output()\n",
    "\n",
    "task45(\"title\")\n",
    "task45(\"abstract\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выводе выше, помимо усредненных оценок качества по выдачам, представлены также статистики по индексам, построенным для разных нормализаторов. \n",
    "\n",
    "Из полученных результатов следует, что качество поиска улучшается при индексации по более длинному полю - *abstract*. Это объясняется ростом вероятности встретить терм из запроса в документе с увеличением размера последнего. Лучшие результаты удалось получить на трех нормализаторах: 'только стемминг', 'только лемматизация', 'стемминг и лемматизация'. При этом все три результата различаются несущественно. Далее будем использовать нормализатор, использующий исключительно лемматизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_text_analyzer = TextAnalyzer(_lang, lemmatizer = WordNetLemmatizer())\n",
    "_index_field = \"abstract\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оптимизировать параметры k1 и b функции BM25. Для этого запустим поиск в каждом узле сетки k1xb=(1.2,2)x(0,1) и сравним качество ответов, используя усредненную F-меру. Проведем два испытания: в первом будем индексировать по полю *title*, а во втором - по *abstract*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------index_field = 'title'------\n",
      "k1: 1.3\n",
      "b: 0.8\n",
      "F-measure: 0.285328152135\n",
      "\n",
      "------index_field = 'abstract'------\n",
      "k1: 1.9\n",
      "b: 0.5\n",
      "F-measure: 0.352592558251\n"
     ]
    }
   ],
   "source": [
    "def task6(index_field):\n",
    "    print \"\\n------index_field = \\'{}\\'------\".format(index_field)\n",
    "    doc_index = index(_text_analyzer, index_field, _doc_db)\n",
    "    \n",
    "    _f1, _k1, _b = None, None, None \n",
    "    for k1 in np.arange(1.2, 2, 0.1):\n",
    "        for b in np.arange(0, 1, 0.1):\n",
    "            ranker = BM25Ranker(k1, b)\n",
    "            search(_text_analyzer, ranker, doc_index, _doc_db, _query_db, 10)\n",
    "            f1 = f1_score()\n",
    "            if _f1 is None or _f1 < f1:\n",
    "                _f1 = f1\n",
    "                _k1 = k1\n",
    "                _b = b\n",
    "                \n",
    "    print(\"k1: {}\\nb: {}\\nF-measure: {}\".format(_k1, _b, _f1))\n",
    "\n",
    "task6(\"title\")\n",
    "task6(\"abstract\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k1 характеризует насколько большой будет разница в релевантности между документом с минимальной и документом с максимальной частотой встречаемости терма. Понятно, что в тексте большей длины будет большая вариативность частот встречаемости термов. Поэтому для 'abstract' лучшее качество ответа мы получили при более высоком значении k1, чем для 'title'.\n",
    "\n",
    "b характеризует то, насколько длина документа влияет на степень его релевантности. Очевидно, что для поля 'abstract' учет фактора длины не играет столь существенной роли, как для поля 'title'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_k1 = 1.9\n",
    "_b = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Задание 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим в функции BM25 IDF-составляющую на $log(\\frac{N}{Nt})$. Оценим качество поиска при использовании модифицированной BM25 формулы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------BM25Ranker------\n",
      "mean precision: 0.298666666667\n",
      "mean recall: 0.43028238359\n",
      "mean F-measure: 0.352592558251\n",
      "MAP@10: 0.360366316033\n",
      "\n",
      "------BM25AltIDFRanker------\n",
      "mean precision: 0.299111111111\n",
      "mean recall: 0.430837939145\n",
      "mean F-measure: 0.353088793365\n",
      "MAP@10: 0.360716404216\n"
     ]
    }
   ],
   "source": [
    "def task7(ranker):\n",
    "    doc_index = index(_text_analyzer, _index_field, _doc_db)\n",
    "    search(_text_analyzer, ranker, doc_index, _doc_db, _query_db, 10)\n",
    "    eval_output()\n",
    "    \n",
    "print \"------BM25Ranker------\"\n",
    "task7(BM25Ranker(_k1, _b))\n",
    "print \"\\n------BM25AltIDFRanker------\"\n",
    "task7(BM25AltIDFRanker(_k1, _b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из результатов выше следует, что при замене формулы качество поиска существенно не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем провести нормализацию RSV величин для документов в процессе поиска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Normalize=False------\n",
      "mean precision: 0.298666666667\n",
      "mean recall: 0.43028238359\n",
      "mean F-measure: 0.352592558251\n",
      "MAP@10: 0.360366316033\n",
      "\n",
      "------Normalize=True------\n",
      "mean precision: 0.0231111111111\n",
      "mean recall: 0.0285820823102\n",
      "mean F-measure: 0.0255570854241\n",
      "MAP@10: 0.0139635900451\n"
     ]
    }
   ],
   "source": [
    "def task8(normalize):\n",
    "    doc_index = index(_text_analyzer, _index_field, _doc_db)\n",
    "    ranker = BM25Ranker(_k1, _b)\n",
    "    search(_text_analyzer, ranker, doc_index, _doc_db, _query_db, 10, normalize)\n",
    "    eval_output()\n",
    "    \n",
    "print \"------Normalize=False------\"\n",
    "task8(False)\n",
    "print \"\\n------Normalize=True------\"\n",
    "task8(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученных результатов следует, что качество поиска существенно снизилось после нормализации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в функцию BM25 множитель, отвечающий за частоту встречаемости термов в запросе: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------index_field = 'abstract'------\n",
      "k2: 0\n",
      "F-measure: 0.352592558251\n"
     ]
    }
   ],
   "source": [
    "def task9():\n",
    "    print \"\\n------index_field = \\'{}\\'------\".format(_index_field)\n",
    "    doc_index = index(_text_analyzer, _index_field, _doc_db)\n",
    "    _k2, _f1 = None, None\n",
    "    for k2 in [0, 25, 50, 75, 100, 250, 500, 750, 1000]:\n",
    "        ranker = BM25Ranker(_k1, _b, k2)\n",
    "        search(_text_analyzer, ranker, doc_index, _doc_db, _query_db, 10)\n",
    "        f1 = f1_score()\n",
    "        if _f1 is None or _f1 < f1:\n",
    "            _f1 = f1\n",
    "            _k2 = k2\n",
    "    print(\"k2: {}\\nF-measure: {}\".format(_k2, _f1))\n",
    "    \n",
    "task9()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ранее найденных лучших значений k1 и b мы получили для k2 лучшую оценку равную 0. Это говорит о том, что влияние частоты встречаемости термов в запросе на качество выдачи минимально. Скорее всего, это связано с тем, что в предложенных запросах термы повторялись не так часто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_k2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим зависимость точности выдачи от заданной величины порога для RSV документа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFyCAYAAACgITN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJoUWwa4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f484e4f04d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------max------\n",
      "\n",
      "threshold: 43\n",
      "precision: 0.706666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def task10():\n",
    "    doc_index = index(_text_analyzer, _index_field, _doc_db)\n",
    "    ranker = BM25Ranker(_k1, _b, _k2)\n",
    "    _threshold, _precis = None, None\n",
    "    xpts, ypts = [], []\n",
    "    for threshold in xrange(10, 50):\n",
    "        search(_text_analyzer, ranker, doc_index, _doc_db, _query_db, 10, False, threshold)\n",
    "        precis = precision()\n",
    "        xpts.append(threshold)\n",
    "        ypts.append(precis)\n",
    "        if _precis < precis:\n",
    "            _threshold = threshold\n",
    "            _precis = precis\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(xpts, ypts)\n",
    "    ax.set_title('Precision(RSV threshold)')\n",
    "    plt.show()\n",
    "    \n",
    "    print \"\\n------max------\"\n",
    "    print \"\\nthreshold: {}\\nprecision: {}\".format(_threshold, _precis)\n",
    "    \n",
    "task10()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика заметно, что полученная зависимость имеет логарифмический характер."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
